{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8581dc5c-450a-4752-afca-e4f195d4972e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "*TAP US30*\n",
    "\n",
    "STREAMING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1f0a3b-a4ca-484c-92f6-3366565f7555",
   "metadata": {},
   "source": [
    "CLIENT PHP\n",
    "\n",
    "Il primo passo della pipeline è quello di creare un client che s'interfacci\n",
    "con l'API di Polygon e faccia richiesta dei dati, considerando la sola giornata \n",
    "precedente. Quest'ultimo sarà mandato in esecuzione su un container.Di seguito, \n",
    "vediamo come ottenere l'opportuno Dockerfile, da cui potremo creare l'immagine \n",
    "che, nel nostro \"docker-compose\", chiameremo \"producer\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5942c313-2c6b-406a-8b42-2acd2d36671c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "FROM alpine\n",
    "RUN apk update && apk add php composer php-fileinfo\n",
    "WORKDIR /app\n",
    "COPY batch_extract.php /app\n",
    "RUN composer require polygon-io/api -W\n",
    "CMD [\"php\", \"batch_extract.php\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969dc170-6bb6-4264-9177-7f414cb8c01a",
   "metadata": {},
   "source": [
    "L'immagine base è quella della versione \"alpine\" di Linux, scelta in quanto\n",
    "tra le più \"leggere\" in termini di spazio sul disco. Il gestore di pacchetti\n",
    "si chiama \"apk\", da cui installiamo le librerie php e composer. La directory \"/app\" nel\n",
    "container è quella in cui copiamo il codice \"batch_extract.php\", il cui\n",
    "contenuto descriveremo in seguito. Eseguiamo il comando \"composer\" per richiedere\n",
    "la libreria da utilizzare nel nostro codice php così da accedere all'API.\n",
    "Dopodichè, una volta partito il container, viene eseguto il comando che\n",
    "innesca l'esecuzione del suddetto codice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f79a18e-868e-4eb6-b8ed-acaa7a8e1017",
   "metadata": {},
   "source": [
    "*batch_extract.php*\n",
    "\n",
    "Innanzitutto, salviamo la API key in una opportuna variabile. Creaiamo un array\n",
    "associativo con come chiave il nome dell'azienda e come valore il settore in cui\n",
    "opera. Dichiariamo poi un oggetto di tipo \"Rest\" sul quale chiameremo una serie di\n",
    "funzioni per prelevare i dati che ci occorrono. Il più importante è il metodo \"get\"\n",
    "che richiede come parametri il nome dell'azienda, un intero, la data di inizio e \n",
    "quella di fine entro cui prelevare le informazioni e l'unità di tempo, che indichiamo\n",
    "come il singolo giorno. In un ciclo for avanzato, scorriamo l'array associativo. ogni\n",
    "12 secondi, inviamo una richiesta attraverso l'API. Salviamo queste informazioni su una\n",
    "variabile che viene passata alla nostra funzione \"write_batch\", insieme al nome \n",
    "dell'azienda e alla categoria a cui appartiene, aggiungendo poi anche l'array\n",
    "associativo stesso. \n",
    "Dopo aver proceduto, alla creazione della cartella e del file, si salva in una variabile\n",
    "l'array alla posizione \"results\" dell'array ottenuto dalla get. Si effettua un ciclo su\n",
    "tutte le n-uple che caratterizzano i dati della specifica azienda, a partire dall'array\n",
    "salvato nella variabile e, dopo aver aggiunto il ticker symbol in questione (dato che \n",
    "altrimenti non sarebbe presente per ogni n-upla, il che creerebbe dei problemi per il \n",
    "successivo processing), si scrive sul file appena creato il contenuto dell'array, \n",
    "sottoforma di json. Fuori dal ciclo, si procede alla chiusura del file.\n",
    "Quello che otterremo è quindi la presenza di 6 cartelle, una per ogni settore a cui le\n",
    "30 aziende appartengono, e ognuna di queste cartelle avrà dei file con estensione \"txt\" \n",
    "composti da n j-son, uno per ogni giorno in cui ogni azienda opera nel mercato azionario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b86c71d-b5c2-446a-aae6-9618617c4bb9",
   "metadata": {},
   "source": [
    "*DATA INGESTION*\n",
    "\n",
    "Innanzitutto, abbiamo utilizzato Fluentd come framework. Esso permette \n",
    "con facilità di accedere a files salvati nel proprio file system e usarli \n",
    "quali source.\n",
    "Dockerfile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf70d3c-f6c1-457e-9cb3-b66c9c7c35fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "FROM fluentd\n",
    "USER root\n",
    "RUN apk add ruby-dev\n",
    "RUN gem install fluent-plugin-kafka --no-doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25eb14a1-8155-4641-b7db-75d803376b69",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Partiamo dall'immagine \"vergine\" di fluentd, scaricata direttamente dalla\n",
    "repository pubblica, per poi installare ruby e gem, quest'ultimo il gestore\n",
    "di pacchetti opportuno per installare il plugin che permette lo scambio di\n",
    "dati tra fluentd e kafka. L'immagine risultante sarà chiamata \"fluentkafka\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052c953a-62c2-458e-ac4f-ef2934ffcbe2",
   "metadata": {},
   "source": [
    "*fluent.conf*\n",
    "\n",
    "La tappa più importante, dopo aver creato opportunemente il\n",
    "Dockerfile e dunque aver avuto a disposizione l'immagine per il container,\n",
    "è quella di scrivere correttamente il file di configurazione. \n",
    "Esistono due tag fondamentali che lo caratterizzano, ovvero \"<source>\" e \n",
    "\"<match>\", rispettivamente a indicare l'input e l'output della data \n",
    "ingestion. \n",
    "Source.\n",
    "\n",
    "L'annotazione \"@type tail\" si utilizza per indicare che si intenda aprire\n",
    "un file. Questi vengono letti, come suggerisce il nome stesso, dall'ultima\n",
    "riga alla prima a meno che, come abbiamo fatto, non si setti la variabile\n",
    "read_from_head a \"true\".  \n",
    "I files da cui stiamo leggendo, come già spiegato nella sezione CLIENT PHP,\n",
    "sono caratterizzati da un json per ogni riga. Dunque, indicheremo \"format\n",
    "json\" affinchè vengano riconosciuti da fluentd come tali.\n",
    "Visto che abbiamo scelto di suddividere le aziende in base al settore,\n",
    "continuiamo a mantenere questi gruppi specificando una source per ognuno\n",
    "di essi. Qualora non li taggassimo opportunemente, non riusciremmo ad \n",
    "utilizzarli in modo specifico all'interno del match. Per cui, per ognuno\n",
    "di essi, scriveremo \"tag\" seguito dal nome del settore.\n",
    "Infine, sarà fondamentale indicare il path da cui prelevarli, così come\n",
    "un path temporaneo, su \"pos_file\", che non indicherà altro che la cartella\n",
    "temporanea in cui si immagazzineranno i dati prima del loro invio in output.\n",
    "Match.\n",
    "\n",
    "L'annotazione \"@type kafka2\" indicherà che l'output verrà reindirizzato a \n",
    "kafka. Ciò è possibile in virtù dell'installazione del plugin che connette\n",
    "fluentd a kafka, da Dockerfile. \n",
    "Il suddetto plugin ci permetterà di specificare due unità fondamentali per\n",
    "kafka, ovvero i brokers e i topics. Abbiamo scelto, per leggibilità, di \n",
    "chiamare ogni broker come \"k-[nomebroker]\" e di bindarlo con la porta\n",
    "\"9092\", la quale sarà mappata a una porta effettiva al di fuori del container\n",
    "dell'istanza di kafka, che coincide con il broker stesso \n",
    "(si veda il docker_compose). Come nome del topic, avremo lo stesso nome\n",
    "del tag specificato in \"<source>\". Avremo quindi un \"<match>\" per\n",
    "ogni \"<source>\". Per specificare quali dati in input inoltreremo, il tag\n",
    "sarà \"<match [nometag]>\".\n",
    "Risulta necessario specificare anche il tipo di file in output, attraverso il\n",
    "tag \"@type json\" all'interno del tag \"<format>\", rigorosamente annidato dentro\n",
    "il match."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65642749-7148-4be0-bbb8-f873b56a712c",
   "metadata": {},
   "source": [
    "DATA DISTRIBUTION\n",
    "Al fine di smistare opportunemente i dati acquisiti, abbiamo usato Apache Kafka. Le unità fondamentali tipiche di questo servizio sono i brokers, i topics, i producers e i consumers. La nostra scelta è stata di creare, come detto, 6 topic, forniti da altrettanti brokers. Ai fini della pipeline, non è necessario istruire producers e consumers (per debug, così da accertarci che i dati effettivamente fossero inviati da fluentd, abbiamo passato argomenti al file \"sh\" del consumer affinchè stampasse su console il contenuto di questi json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606538b7-450c-4d5e-b871-d45a4af3436b",
   "metadata": {},
   "source": [
    "Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13337bc0-7513-4e44-9255-600a674c9043",
   "metadata": {},
   "outputs": [],
   "source": [
    "FROM bitnami/kafka\n",
    "RUN rm -f /bitnami/kafka/data/.lock\n",
    "COPY init.sh /opt/bitnami/scripts/kafka\n",
    "COPY init /opt/bitnami/scripts/kafka\n",
    "CMD [\"/opt/bitnami/scripts/kafka/init\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08b087f-d60a-43a5-81e4-22956757856b",
   "metadata": {},
   "source": [
    "Ognuna della 6 istanze di kafka, identificate da un broker per ciascuna, si basa su questa immagine. Dopo aver scaricato l'immagine ufficiale di kafka, si aggiunge lo script \"init.sh\" all'interno del file system del container, così come \"init\" (il file compilato basato sul codice in c che ci permette un'opportuna temporizzazione tra il deployment del server e la creazione dei topics, rigorosamente l'una dopo l'altra, eseguendo prima lo script run.sh e poi init.sh) e si esegue \"init\".\n",
    "L'immagine risultante sarà chiamata \"kafka_init\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4cd61e-34f3-44a0-895b-2c8fd81dc827",
   "metadata": {},
   "source": [
    "Zookeeper e ZooNavigator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a1059c-bdbe-437e-87a6-edcb1b71e0c5",
   "metadata": {},
   "source": [
    "Per navigare agilmente tra l'amplia offerta di servizi di Kafka, è sempre necessario che con i server kafka si attivi anche un server zookeeper e un altro server, nel nostro caso \"zoonavigator\", che consenta l'accesso via browser dell'interfaccia grafica di zookeeper. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea25828d-617d-46d3-96ac-3e0e70cd8e52",
   "metadata": {},
   "source": [
    "Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fd6090-5fd2-4e0c-9ab3-d3f815e52d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "FROM zookeeper\n",
    "RUN /apache-zookeeper-3.9.1-bin/bin/zkCli.sh << \"delete /brokers/ids/*\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b88b96-3bc8-44b2-a820-1a34046dad4e",
   "metadata": {},
   "source": [
    "Questo Dockerfile parte dall'immagine ufficiale di zookeeper. L'immagine che costituisce sarà chiamata \"zookeeper_clean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56588605-5ca1-42a6-9b3a-4f31127fd54b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
