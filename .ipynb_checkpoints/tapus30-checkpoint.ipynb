{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8581dc5c-450a-4752-afca-e4f195d4972e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "*TAP US30*\n",
    "\n",
    "STREAMING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1f0a3b-a4ca-484c-92f6-3366565f7555",
   "metadata": {},
   "source": [
    "CLIENT PHP\n",
    "\n",
    "Il primo passo della pipeline è quello di creare un client che s'interfacci\n",
    "con l'API di Polygon e faccia richiesta dei dati, considerando la sola giornata \n",
    "precedente. Quest'ultimo sarà mandato in esecuzione su un container.Di seguito, \n",
    "vediamo come ottenere l'opportuno Dockerfile, da cui potremo creare l'immagine \n",
    "che, nel nostro \"docker-compose\", chiameremo \"producer\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5942c313-2c6b-406a-8b42-2acd2d36671c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "FROM alpine\n",
    "RUN apk update && apk add php composer php-fileinfo\n",
    "WORKDIR /app\n",
    "COPY batch_extract.php /app\n",
    "RUN composer require polygon-io/api -W\n",
    "CMD [\"php\", \"batch_extract.php\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969dc170-6bb6-4264-9177-7f414cb8c01a",
   "metadata": {},
   "source": [
    "L'immagine base è quella della versione \"alpine\" di Linux, scelta in quanto\n",
    "tra le più \"leggere\" in termini di spazio sul disco. Il gestore di pacchetti\n",
    "si chiama \"apk\", da cui installiamo le librerie php e composer. La directory \"/app\" nel\n",
    "container è quella in cui copiamo il codice \"batch_extract.php\", il cui\n",
    "contenuto descriveremo in seguito. Eseguiamo il comando \"composer\" per richiedere\n",
    "la libreria da utilizzare nel nostro codice php così da accedere all'API.\n",
    "Dopodichè, una volta partito il container, viene eseguto il comando che\n",
    "innesca l'esecuzione del suddetto codice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f79a18e-868e-4eb6-b8ed-acaa7a8e1017",
   "metadata": {},
   "source": [
    "*batch_extract.php*\n",
    "\n",
    "Innanzitutto, salviamo la API key in una opportuna variabile. Creaiamo un array\n",
    "associativo con come chiave il nome dell'azienda e come valore il settore in cui\n",
    "opera. Dichiariamo poi un oggetto di tipo \"Rest\" sul quale chiameremo una serie di\n",
    "funzioni per prelevare i dati che ci occorrono. Il più importante è il metodo \"get\"\n",
    "che richiede come parametri il nome dell'azienda, un intero, la data di inizio e \n",
    "quella di fine entro cui prelevare le informazioni e l'unità di tempo, che indichiamo\n",
    "come il singolo giorno. In un ciclo for avanzato, scorriamo l'array associativo. ogni\n",
    "12 secondi, inviamo una richiesta attraverso l'API. Salviamo queste informazioni su una\n",
    "variabile che viene passata alla nostra funzione \"write_batch\", insieme al nome \n",
    "dell'azienda e alla categoria a cui appartiene, aggiungendo poi anche l'array\n",
    "associativo stesso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b86c71d-b5c2-446a-aae6-9618617c4bb9",
   "metadata": {},
   "source": [
    "*DATA INGESTION*\n",
    "\n",
    "Innanzitutto, abbiamo utilizzato Fluentd come framework. Esso permette \n",
    "con facilità di accedere a files salvati nel proprio file system e usarli \n",
    "quali source.\n",
    "Dockerfile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf70d3c-f6c1-457e-9cb3-b66c9c7c35fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "FROM fluentd\n",
    "USER root\n",
    "RUN apk add ruby-dev\n",
    "RUN gem install fluent-plugin-kafka --no-doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25eb14a1-8155-4641-b7db-75d803376b69",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Partiamo dall'immagine \"vergine\" di fluentd, scaricata direttamente dalla\n",
    "repository pubblica, per poi installare ruby e gem, quest'ultimo il gestore\n",
    "di pacchetti opportuno per installare il plugin che permette lo scambio di\n",
    "dati tra fluentd e kafka. L'immagine risultante sarà chiamata \"fluentkafka\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052c953a-62c2-458e-ac4f-ef2934ffcbe2",
   "metadata": {},
   "source": [
    "*fluent.conf*\n",
    "\n",
    "La tappa più importante, dopo aver creato opportunemente il\n",
    "Dockerfile e dunque aver avuto a disposizione l'immagine per il container,\n",
    "è quella di scrivere correttamente il file di configurazione. \n",
    "Esistono due tag fondamentali che lo caratterizzano, ovvero \"<source>\" e \n",
    "\"<match>\", rispettivamente a indicare l'input e l'output della data \n",
    "ingestion. \n",
    "Source.\n",
    "\n",
    "L'annotazione \"@type tail\" si utilizza per indicare che si intenda aprire\n",
    "un file. Questi vengono letti, come suggerisce il nome stesso, dall'ultima\n",
    "riga alla prima a meno che, come abbiamo fatto, non si setti la variabile\n",
    "read_from_head a \"true\".  \n",
    "I files da cui stiamo leggendo, come già spiegato nella sezione CLIENT PHP,\n",
    "sono caratterizzati da un json per ogni riga. Dunque, indicheremo \"format\n",
    "json\" affinchè vengano riconosciuti da fluentd come tali.\n",
    "Visto che abbiamo scelto di suddividere le aziende in base al settore,\n",
    "continuiamo a mantenere questi gruppi specificando una source per ognuno\n",
    "di essi. Qualora non li taggassimo opportunemente, non riusciremmo ad \n",
    "utilizzarli in modo specifico all'interno del match. Per cui, per ognuno\n",
    "di essi, scriveremo \"tag\" seguito dal nome del settore.\n",
    "Infine, sarà fondamentale indicare il path da cui prelevarli, così come\n",
    "un path temporaneo, su \"pos_file\", che non indicherà altro che la cartella\n",
    "temporanea in cui si immagazzineranno i dati prima del loro invio in output.\n",
    "Match.\n",
    "\n",
    "L'annotazione \"@type kafka2\" indicherà che l'output verrà reindirizzato a \n",
    "kafka. Ciò è possibile in virtù dell'installazione del plugin che connette\n",
    "fluentd a kafka, da Dockerfile. \n",
    "Il suddetto plugin ci permetterà di specificare due unità fondamentali per\n",
    "kafka, ovvero i brokers e i topics. Abbiamo scelto, per leggibilità, di \n",
    "chiamare ogni broker come \"k-[nomebroker]\" e di bindarlo con la porta\n",
    "\"9092\", la quale sarà mappata a una porta effettiva al di fuori del container\n",
    "dell'istanza di kafka, che coincide con il broker stesso \n",
    "(si veda il docker_compose). Come nome del topic, avremo lo stesso nome\n",
    "del tag specificato in \"<source>\". Avremo quindi un \"<match>\" per\n",
    "ogni \"<source>\". Per specificare quali dati in input inoltreremo, il tag\n",
    "sarà \"<match [nometag]>\".\n",
    "Risulta necessario specificare anche il tipo di file in output, attraverso il\n",
    "tag \"@type json\" all'interno del tag \"<format>\", rigorosamente annidato dentro\n",
    "il match."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
