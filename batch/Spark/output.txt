23/11/06 12:43:51 WARN Utils: Your hostname, durchbruchmuller resolves to a loopback address: 127.0.1.1; using 192.168.1.18 instead (on interface enp42s0)
23/11/06 12:43:51 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
:: loading settings :: url = jar:file:/home/romae/Scaricati/spark-3.5.0-bin-hadoop3/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
Ivy Default Cache set to: /home/romae/.ivy2/cache
The jars for the packages stored in: /home/romae/.ivy2/jars
org.apache.spark#spark-streaming-kafka-0-8_2.11 added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-c7208f53-33c7-45d1-af7f-38e5accee6c4;1.0
        confs: [default]
        found org.apache.spark#spark-streaming-kafka-0-8_2.11;2.3.0 in central
        found org.apache.kafka#kafka_2.11;0.8.2.1 in central
        found org.scala-lang.modules#scala-xml_2.11;1.0.2 in central
        found com.yammer.metrics#metrics-core;2.2.0 in central
        found org.slf4j#slf4j-api;1.7.16 in central
        found org.scala-lang.modules#scala-parser-combinators_2.11;1.0.4 in central
        found com.101tec#zkclient;0.3 in central
        found log4j#log4j;1.2.17 in central
        found org.apache.kafka#kafka-clients;0.8.2.1 in central
        found net.jpountz.lz4#lz4;1.2.0 in central
        found org.xerial.snappy#snappy-java;1.1.2.6 in central
        found org.spark-project.spark#unused;1.0.0 in central
:: resolution report :: resolve 200ms :: artifacts dl 6ms
        :: modules in use:
        com.101tec#zkclient;0.3 from central in [default]
        com.yammer.metrics#metrics-core;2.2.0 from central in [default]
        log4j#log4j;1.2.17 from central in [default]
        net.jpountz.lz4#lz4;1.2.0 from central in [default]
        org.apache.kafka#kafka-clients;0.8.2.1 from central in [default]
        org.apache.kafka#kafka_2.11;0.8.2.1 from central in [default]
        org.apache.spark#spark-streaming-kafka-0-8_2.11;2.3.0 from central in [default]
        org.scala-lang.modules#scala-parser-combinators_2.11;1.0.4 from central in [default]
        org.scala-lang.modules#scala-xml_2.11;1.0.2 from central in [default]
        org.slf4j#slf4j-api;1.7.16 from central in [default]
        org.spark-project.spark#unused;1.0.0 from central in [default]
        org.xerial.snappy#snappy-java;1.1.2.6 from central in [default]
        ---------------------------------------------------------------------
        |                  |            modules            ||   artifacts   |
        |       conf       | number| search|dwnlded|evicted|| number|dwnlded|
        ---------------------------------------------------------------------
        |      default     |   12  |   0   |   0   |   0   ||   12  |   0   |
        ---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-c7208f53-33c7-45d1-af7f-38e5accee6c4
        confs: [default]
        0 artifacts copied, 12 already retrieved (0kB/5ms)
23/11/06 12:43:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Traceback (most recent call last):
  File "/home/romae/tapUS30/Spark/sparktest.py", line 6, in <module>
    from pyspark.streaming.kafka import KafkaUtils
ModuleNotFoundError: No module named 'pyspark.streaming.kafka'
23/11/06 12:43:52 INFO ShutdownHookManager: Shutdown hook called
23/11/06 12:43:52 INFO ShutdownHookManager: Deleting directory /tmp/spark-c59173b6-0eb4-40b2-a884-a2f1c55ff03d
